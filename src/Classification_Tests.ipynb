{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "spiegazione test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import xml.etree.ElementTree as ET\n",
    "import nltk\n",
    "from nltk.stem.snowball import ItalianStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn import svm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import collections\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CarWordsHandler:\n",
    "    # https://github.com/n8barr/automotive-model-year-data\n",
    "    def __init__(self, cars_file):\n",
    "        self.brands_list = set()\n",
    "        self.models_list = set()\n",
    "        f = open(cars_file, \"r\")\n",
    "        cars_list = f.read().splitlines()\n",
    "        for i in range(len(cars_list)):\n",
    "            brand = cars_list[i].split(',')[1][2:-1].lower()\n",
    "            model = cars_list[i].split(',')[2][2:-2].lower()\n",
    "            self.brands_list.add(brand)\n",
    "            self.models_list.add(model)\n",
    "        # remove some useless models\n",
    "        self.models_list.remove('i')\n",
    "        self.models_list.remove('gli')\n",
    "        self.models_list.remove('estate')\n",
    "        self.brands_list = list(self.brands_list)\n",
    "        self.models_list = list(self.models_list)\n",
    "        self.brands_list.sort()\n",
    "        self.models_list.sort()\n",
    "    \n",
    "    # binary search to get if a word is a brand \n",
    "    def isBrand(self, word):\n",
    "        word = word.lower()\n",
    "        first = 0\n",
    "        last = len(self.brands_list) -1\n",
    "        while first < last:\n",
    "            mid = int((last + first) / 2)\n",
    "            if word == self.brands_list[mid]:\n",
    "                return True\n",
    "            elif word < self.brands_list[mid]:\n",
    "                last = mid\n",
    "            elif word > self.brands_list[mid]:\n",
    "                first = mid\n",
    "            if last-first == 1:\n",
    "                if self.brands_list[first] == word or self.brands_list[last] == word:\n",
    "                    return True\n",
    "                else:\n",
    "                    return False\n",
    "    # binary search to get if a word is a brand \n",
    "    def isModel(self, word):\n",
    "        word = word.lower()\n",
    "        first = 0\n",
    "        last = len(self.models_list) -1\n",
    "        while first < last:\n",
    "            mid = int((last + first) / 2)\n",
    "            if word == self.models_list[mid]:\n",
    "                return True\n",
    "            elif word < self.models_list[mid]:\n",
    "                last = mid\n",
    "            elif word > self.models_list[mid]:\n",
    "                first = mid\n",
    "            if last-first == 1:\n",
    "                if self.models_list[first] == word or self.models_list[last] == word:\n",
    "                    return True\n",
    "                else:\n",
    "                    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding issues\n",
    "def correctEncodings(comment):\n",
    "    fin_comment = comment\n",
    "    fin_comment = re.sub('Ã¨', 'è', fin_comment)\n",
    "    fin_comment = re.sub('Ã©', 'é', fin_comment)\n",
    "    fin_comment = re.sub('Ã¬', 'ì', fin_comment)\n",
    "    fin_comment = re.sub('Ã²', 'ò', fin_comment)\n",
    "    fin_comment = re.sub('Ã¹', 'ù', fin_comment)\n",
    "    fin_comment = re.sub('Ã', 'à', fin_comment)\n",
    "    return fin_comment\n",
    "# recognize an URL\n",
    "def isURL(word):\n",
    "    # http://forum.rusconi.it/gentemotori/viewtopic.php ? t=434&sid=57c88f1b507d8f57717ea18e74e25324Â \n",
    "    return len(re.findall(\"^((http(s){0,1}://)|(www.))\\S+$\", word)) > 0\n",
    "# recognize an image tag\n",
    "def isPicture(word):\n",
    "    return len(re.findall(\"^<img.*>$\", word)) > 0\n",
    "# remove punctation\n",
    "def removePunctation(comment):\n",
    "    return re.sub(r'\\s{2,}', ' ', str(re.sub(r'[\\'\\\"\\,\\.,\\:\\-]', ' ', comment)))\n",
    "# fix issues on urls\n",
    "def replaceURLs(comment):\n",
    "    return str(re.sub(r'(http(s){0,1}://|www.)(([^\\s]+)|/)+((\\s\\?\\s)[^\\s]+){0,1}', 'URL', comment)).replace(u'\\xa0', u' ')\n",
    "# replace images\n",
    "def replaceIMGs(comment):\n",
    "    return str(re.sub(r'<img.+>', 'IMG', comment))\n",
    "# replace brands\n",
    "def replaceBrands(cwhandler, comment):\n",
    "    tokens = comment.split(' ')\n",
    "    for i in range(len(tokens)):\n",
    "        if cwhandler.isBrand(tokens[i]):\n",
    "            tokens[i] = 'BRAND'\n",
    "    return ' '.join(tokens)\n",
    "# replace models\n",
    "def replaceModels(cwhandler, comment):\n",
    "    tokens = comment.split(' ')\n",
    "    for i in range(len(tokens)):\n",
    "        if cwhandler.isModel(tokens[i]):\n",
    "            tokens[i] = 'MODEL'\n",
    "    return ' '.join(tokens)\n",
    "# replace question marks\n",
    "def replaceQMarks(comment):\n",
    "    comment = re.sub(r'\\?{2,}', ' MULTI_QMARK', comment)\n",
    "    comment = re.sub(r'\\?', ' QMARK', comment)\n",
    "    return comment\n",
    "# replace esclamation marks\n",
    "def replaceEMarks(comment):\n",
    "    comment = re.sub(r'\\!{2,}', ' MULTI_EMARK', comment)\n",
    "    comment = re.sub(r'\\!', ' EMARK', comment)\n",
    "    return comment\n",
    "# remove character repetitions\n",
    "def removeRepeat(comment):\n",
    "    return re.sub(r'(a-zA-Z)\\1{2,}', r'\\1\\1\\1', comment)\n",
    "# replace speed\n",
    "def replaceSpeed(comment):\n",
    "    return re.sub(r'([0-9\\.*]+(\\s*(\\-|\\/|\\s)\\s*)+){0,1}[0-9\\.*]+(\\s*)(km\\/h|mph)', 'SPEED', comment)\n",
    "# replace consumption\n",
    "def replaceConsumption(comment):\n",
    "    return re.sub(r'([0-9\\.*]+(\\s*(\\-|\\/|\\s)\\s*)+){0,1}[0-9\\.*]+(\\s*)(km\\/l|mpg)', 'CONSUMPTION', comment)\n",
    "# replace weight\n",
    "def replaceWeight(comment):\n",
    "    return re.sub(r'[0-9\\.*]+(\\s*)(kg|tonnellate|ton|chili|kili)', 'WEIGHT', comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ItalianWordsHandler:\n",
    "    # https://dspace-clarin-it.ilc.cnr.it/repository/xmlui/handle/20.500.11752/ILC-73\n",
    "    def __init__(self, words_file):\n",
    "        # words information\n",
    "        self.words_dict = dict()\n",
    "        root = ET.parse(words_file).getroot()\n",
    "        for entry in root.findall('Lexicon/LexicalEntry'):\n",
    "            word = entry.find('Lemma').get('writtenForm')\n",
    "            pos = entry.get('partOfSpeech')\n",
    "            senti = entry.find('Sense/Sentiment').get('polarity')\n",
    "            conf = entry.find('Sense/Confidence').get('score')\n",
    "            self.words_dict[word] = {'POS': pos, 'Sentiment': senti, 'Confidence': conf}\n",
    "        # stemmer\n",
    "        self.it_stem = ItalianStemmer()\n",
    "        \n",
    "    # get word info. None if not exists\n",
    "    def getWordInfo(self, word):\n",
    "        # fields: POS, Sentiment, Confidence\n",
    "        return self.words_dict.get(word)\n",
    "    \n",
    "    # italian stemmer http://snowball.tartarus.org/algorithms/italian/stemmer.html\n",
    "    def stem(self, word):\n",
    "        return self.it_stem.stem(word)\n",
    "    \n",
    "    # correct words\n",
    "    def correctWords(self, text):\n",
    "        # not yet implemented\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocessor:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.cwh = CarWordsHandler('resources/cars_data.sql')\n",
    "        self.iwh = ItalianWordsHandler('resources/ita_opeNER.xml')\n",
    "    # preprocess text\n",
    "    # allowed methods: word, swnt, pos\n",
    "    # ner (named entity recognition), replacing for instance 100 km/h with SPEED\n",
    "    def preprocessText(self, text, method='word', use_stemmer=False, ner=False):\n",
    "        if method not in ['word', 'pos', 'swnt']:\n",
    "            raise ValueError('Method not recognized. Select from word, swnt, pos')\n",
    "        # correct encodings (not yet implemented)\n",
    "        fin_text = correctEncodings(text)\n",
    "        # remove punctation\n",
    "        fin_text = removePunctation(fin_text)\n",
    "        # some basic preprocessing\n",
    "        fin_text = fin_text.lower()\n",
    "        # correct words (not yet)\n",
    "        fin_text = self.iwh.correctWords(fin_text)\n",
    "        # manage repetitions\n",
    "        fin_text = removeRepeat(fin_text)\n",
    "        # manage punctation\n",
    "        fin_text = replaceQMarks(fin_text)\n",
    "        fin_text = replaceEMarks(fin_text)\n",
    "        # manage URLs\n",
    "        fin_text = replaceURLs(fin_text)\n",
    "        # manage Images\n",
    "        fin_text = replaceIMGs(fin_text)\n",
    "        # NOW DEPENDS ON NER\n",
    "        if ner:\n",
    "            # manage brands and models\n",
    "            fin_text = replaceBrands(self.cwh, fin_text)\n",
    "            fin_text = replaceModels(self.cwh, fin_text)\n",
    "            # manage speed consumption and weight\n",
    "            fin_text = replaceSpeed(fin_text)\n",
    "            fin_text = replaceConsumption(fin_text)\n",
    "            fin_text = replaceWeight(fin_text)\n",
    "        # NOW DEPENDS ON METHOD\n",
    "        if method == 'word':\n",
    "            # just do nothing except eventually stemming\n",
    "            if use_stemmer:\n",
    "                tokens = fin_text.split(' ')\n",
    "                fin_text = ' '.join([t if t.isupper() else self.iwh.stem(t) for t in tokens]) \n",
    "        elif method == 'swnt':\n",
    "            tokens = fin_text.split(' ')\n",
    "            swnt_tokens = []\n",
    "            for t in tokens:\n",
    "                info = self.iwh.getWordInfo(t)\n",
    "                if info == None or info['Sentiment'] == None:\n",
    "                    swnt_tokens.append(t)\n",
    "                else:\n",
    "                    # confidence 0-100\n",
    "                    swnt_tokens.append(str(info['Sentiment'])[:3].upper() + '_' + str(int(float(info['Confidence'])*10)))\n",
    "            fin_text = ' '.join(swnt_tokens)\n",
    "            # stemmer\n",
    "            if use_stemmer:\n",
    "                tokens = fin_text.split(' ')\n",
    "                fin_text = ' '.join([t if t.isupper() else self.iwh.stem(t) for t in tokens]) \n",
    "        elif method == 'pos':\n",
    "            tokens = fin_text.split(' ')\n",
    "            pos_tokens = []\n",
    "            # pos\n",
    "            for t in tokens:\n",
    "                info = self.iwh.getWordInfo(t)\n",
    "                if info == None or info['POS'] == None:\n",
    "                    # unknown tag\n",
    "                    pos_tokens.append('UNK')\n",
    "                else:\n",
    "                    pos_tokens.append(str(info['POS']).upper())\n",
    "            # pos_word\n",
    "            for t in tokens:\n",
    "                info = self.iwh.getWordInfo(t)\n",
    "                if info == None or info['POS'] == None:\n",
    "                    pos_tokens.append('UNK_' + str(t))\n",
    "                else:\n",
    "                    pos_tokens.append(str(info['POS']).upper() + '_' + str(t))\n",
    "                    \n",
    "            fin_text = ' '.join(pos_tokens)\n",
    "            # stemmer\n",
    "            if use_stemmer:\n",
    "                tokens = fin_text.split(' ')\n",
    "                fin_text = ' '.join([t if t.isupper() else self.iwh.stem(t) for t in tokens]) \n",
    "        \n",
    "        return str(re.sub(r'\\s{2,}', ' ', fin_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vectorizer:\n",
    "    \n",
    "    def __init__(self, list_comments, method='bow', max_features=1000, ngrams=2, just_presence=False):\n",
    "        if method not in ['bow', 'tfidf']:\n",
    "            raise ValueError('Method not recognized. Select from bow, tfidf')\n",
    "        if method == 'bow':\n",
    "            self.vectorizer = CountVectorizer(ngram_range=(1,ngrams), binary=just_presence, lowercase=False, max_features=max_features)\n",
    "        elif method == 'tfidf':\n",
    "            self.vectorizer = TfidfVectorizer(ngram_range=(1,ngrams), lowercase=False, max_features=max_features)\n",
    "        # fit vectorizer\n",
    "        self.vectorizer.fit(list_comments)          \n",
    "        \n",
    "        \n",
    "        '''\n",
    "        self.list_comments = list_comments\n",
    "        # initialize tfidf weights\n",
    "        self.idf_dict = {}\n",
    "        idf_dict_uni = {}\n",
    "        idf_dict_big = {}\n",
    "        # unigrams\n",
    "        for comment in list_comments:\n",
    "            tokens = list(set(comment.split()))\n",
    "            for t in tokens:\n",
    "                if idf_dict_uni.get(t) != None:\n",
    "                    idf_dict_uni[t] = idf_dict_uni[t] + 1\n",
    "                else:\n",
    "                    idf_dict_uni[t] = 1\n",
    "        # bigrams\n",
    "        for comment in list_comments:\n",
    "            tokens = comment.split()\n",
    "            for i in range(len(tokens) -2):\n",
    "                big = (tokens[i], tokens[i+1])\n",
    "                if idf_dict_big.get(big) != None:\n",
    "                    idf_dict_big[big] = idf_dict_big[big] + 1\n",
    "                else:\n",
    "                    idf_dict_big[big] = 1\n",
    "        # cut most frequent\n",
    "        idf_dict_uni = Counter(idf_dict_uni).most_common(most_common_unigrams)\n",
    "        idf_dict_big = Counter(idf_dict_big).most_common(most_common_bigrams)\n",
    "        self.idf_dict.update(idf_dict_uni)\n",
    "        self.idf_dict.update(idf_dict_big)\n",
    "        '''\n",
    "        \n",
    "    def vectorize(self, comment):\n",
    "        \n",
    "        return self.vectorizer.transform([comment])\n",
    "        \n",
    "        '''\n",
    "        if method not in ['bow', 'tfidf']:\n",
    "            raise ValueError('Method not recognized. Select from bow, tfidf')\n",
    "        unigrams = comment.split(' ')\n",
    "        bigrams = []\n",
    "        for i in range(len(unigrams) -2):\n",
    "            bigrams.append((unigrams[i], unigrams[i+1]))\n",
    "        if method == 'bow':\n",
    "            bow_dict = dict.fromkeys(self.idf_dict, 0)\n",
    "            for u in unigrams + bigrams:\n",
    "                if bow_dict.get(u) != None:\n",
    "                    if just_presence:\n",
    "                        bow_dict[u] = 1\n",
    "                    else:\n",
    "                        bow_dict[u] = bow_dict[u] +1\n",
    "            return list(bow_dict.values())\n",
    "        elif method == 'tfidf':\n",
    "            tf_dict = dict.fromkeys(self.idf_dict, 0)\n",
    "            for u in unigrams + bigrams:\n",
    "                if tf_dict.get(u) != None:\n",
    "                    tf_dict[u] = tf_dict[u] +1\n",
    "        '''\n",
    "        \n",
    "    def get_feature_names(self):\n",
    "        return self.vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vectorization Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ciao', 'ciao come', 'ciao questa', 'come', 'come scrive', 'come va', 'falso', 'lo', 'lo so', 'me', 'me falso', 'non', 'non lo', 'per', 'per me', 'questa', 'questa tastiera', 'scrive', 'scrive ciao', 'so', 'so per', 'tastiera', 'va', 'vediamo', 'vediamo come']\n",
      "  (0, 22)\t0.41197297843389025\n",
      "  (0, 5)\t0.41197297843389025\n",
      "  (0, 3)\t0.3133160688892059\n",
      "  (0, 1)\t0.41197297843389025\n",
      "  (0, 0)\t0.6266321377784118\n"
     ]
    }
   ],
   "source": [
    "v = Vectorizer(list_comments=['ciao come va ?', 'vediamo come scrive ciao questa tastiera', 'non lo so, per me è falso'], method='tfidf', max_features=100, ngrams=2, just_presence=True)\n",
    "print(v.get_feature_names())\n",
    "print(v.vectorize('ciao ciao come va ?'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sono reali calcolati nel arco del tutto anno nel estate qualcosa in piÃ¹ causa gomme di 17\" e climatizzatore nel inverno un po di meno. Per quanto riguarda le autostrade quelle che percorro io principalmente la A4 e molto congestionata cosi spesso la media e 110-115 km/h che ovviamente influisce positivamente a i consumi. Ma quello che mi piace di piÃ¹ Ã¨ assenza dei guasti. Sulla vecchia Accord il primo guasto lo ho avuto a 200000 km si Ã¨ rotto il termostato della clima. Ogni tanto faccio giro di altri forum e leggo delle turbine rotte catene di distribuzione progettate male iniettori fatti male mah nel 2015 per me sono le cose incomprensibili . Con tutti gli difetti che puÃ² avere preferisco la Honda. \n",
      "##########################################################################################\n",
      "sono reali calcolati nel arco del tutto anno nel estate qualcosa in più causa gomme di 17 e climatizzatore nel inverno un po di meno per quanto riguarda le autostrade quelle che percorro io principalmente la a4 e molto congestionata cosi spesso la media e 110 115 km/h che ovviamente influisce positivamente a i consumi ma quello che mi piace di più è assenza dei guasti sulla vecchia accord il primo guasto lo ho avuto a 200000 km si è rotto il termostato della clima ogni tanto faccio giro di altri forum e leggo delle turbine rotte catene di distribuzione progettate male iniettori fatti male mah nel 2015 per me sono le cose incomprensibili con tutti gli difetti che può avere preferisco la honda \n",
      "##########################################################################################\n",
      "sono POS_2 calcolati nel NEU_2 del NEU_2 anno nel estate qualcosa in più POS_5 gomme di 17 e climatizzatore nel inverno un po di meno per quanto riguarda le autostrade quelle che percorro POS_1 principalmente la a4 e molto congestionata cosi spesso la NEU_2 e 110 115 km/h che ovviamente influisce POS_10 a i consumi ma quello che mi piace di più è NEG_6 dei guasti sulla vecchia accord il POS_6 NEG_5 lo ho avuto a 200000 km si è NEG_5 il termostato della clima ogni NEG_5 faccio NEU_2 di altri forum e leggo delle turbine rotte catene di NEU_5 progettate NEG_6 iniettori fatti NEG_6 mah nel 2015 per me sono le cose incomprensibili con tutti gli difetti che può NEG_5 preferisco la honda \n",
      "##########################################################################################\n",
      "UNK NOUN UNK UNK NOUN UNK NOUN UNK UNK UNK UNK UNK ADV NOUN UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK ADV UNK UNK UNK UNK UNK UNK UNK UNK NOUN UNK UNK UNK UNK ADV UNK UNK UNK UNK NOUN UNK UNK UNK UNK UNK UNK UNK ADV UNK UNK UNK UNK UNK UNK UNK UNK UNK ADV UNK NOUN UNK UNK UNK UNK UNK UNK ADJ NOUN UNK UNK UNK UNK UNK UNK UNK UNK ADJ UNK UNK UNK UNK UNK ADJ UNK NOUN UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK NOUN UNK NOUN UNK UNK NOUN UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK VERB UNK UNK UNK UNK UNK_sono NOUN_reali UNK_calcolati UNK_nel NOUN_arco UNK_del NOUN_tutto UNK_anno UNK_nel UNK_estate UNK_qualcosa UNK_in ADV_più NOUN_causa UNK_gomme UNK_di UNK_17 UNK_e UNK_climatizzatore UNK_nel UNK_inverno UNK_un UNK_po UNK_di ADV_meno UNK_per UNK_quanto UNK_riguarda UNK_le UNK_autostrade UNK_quelle UNK_che UNK_percorro NOUN_io UNK_principalmente UNK_la UNK_a4 UNK_e ADV_molto UNK_congestionata UNK_cosi UNK_spesso UNK_la NOUN_media UNK_e UNK_110 UNK_115 UNK_km/h UNK_che UNK_ovviamente UNK_influisce ADV_positivamente UNK_a UNK_i UNK_consumi UNK_ma UNK_quello UNK_che UNK_mi UNK_piace UNK_di ADV_più UNK_è NOUN_assenza UNK_dei UNK_guasti UNK_sulla UNK_vecchia UNK_accord UNK_il ADJ_primo NOUN_guasto UNK_lo UNK_ho UNK_avuto UNK_a UNK_200000 UNK_km UNK_si UNK_è ADJ_rotto UNK_il UNK_termostato UNK_della UNK_clima UNK_ogni ADJ_tanto UNK_faccio NOUN_giro UNK_di UNK_altri UNK_forum UNK_e UNK_leggo UNK_delle UNK_turbine UNK_rotte UNK_catene UNK_di NOUN_distribuzione UNK_progettate NOUN_male UNK_iniettori UNK_fatti NOUN_male UNK_mah UNK_nel UNK_2015 UNK_per UNK_me UNK_sono UNK_le UNK_cose UNK_incomprensibili UNK_con UNK_tutti UNK_gli UNK_difetti UNK_che UNK_può VERB_avere UNK_preferisco UNK_la UNK_honda UNK_\n"
     ]
    }
   ],
   "source": [
    "text = 'Sono reali calcolati nel arco del tutto anno nel estate qualcosa in piÃ¹ causa gomme di 17\" e climatizzatore nel inverno un po di meno. Per quanto riguarda le autostrade quelle che percorro io principalmente la A4 e molto congestionata cosi spesso la media e 110-115 km/h che ovviamente influisce positivamente a i consumi. Ma quello che mi piace di piÃ¹ Ã¨ assenza dei guasti. Sulla vecchia Accord il primo guasto lo ho avuto a 200000 km si Ã¨ rotto il termostato della clima. Ogni tanto faccio giro di altri forum e leggo delle turbine rotte catene di distribuzione progettate male iniettori fatti male mah nel 2015 per me sono le cose incomprensibili . Con tutti gli difetti che puÃ² avere preferisco la Honda. '\n",
    "print(text)\n",
    "print('##########################################################################################')\n",
    "p = Preprocessor()\n",
    "print(p.preprocessText(text, ner=False, use_stemmer=False, method='word'))\n",
    "print('##########################################################################################')\n",
    "print(p.preprocessText(text, ner=False, use_stemmer=False, method='swnt'))\n",
    "print('##########################################################################################')\n",
    "print(p.preprocessText(text, ner=False, use_stemmer=False, method='pos'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each comment divide Text from Quote by setting _TEXT or _QUOTE at the end of each word. This after preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_text_quote(text, quote):\n",
    "    text_tokens = text.split(' ')\n",
    "    quote_tokens = quote.split(' ')\n",
    "    combined_tokens = []\n",
    "    for tt in text_tokens:\n",
    "        combined_tokens.append(str(tt) + '_TEXT')\n",
    "    for qt in quote_tokens:\n",
    "        combined_tokens.append(str(qt) + '_QUOTE')\n",
    "    return ' '.join(combined_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bene_TEXT grazie_TEXT ciao_QUOTE come_QUOTE va_QUOTE\n"
     ]
    }
   ],
   "source": [
    "print(combine_text_quote('Bene grazie', 'ciao come va'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TESTO</th>\n",
       "      <th>(Testo Citato)</th>\n",
       "      <th>Brand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Allora il problema è che non sono aggiornati i...</td>\n",
       "      <td></td>\n",
       "      <td>irrilevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>E' virgolettato appositamente.... E soprattutt...</td>\n",
       "      <td></td>\n",
       "      <td>irrilevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mah io sulla mappa ev-way ho visto solo tipo 2...</td>\n",
       "      <td>'Inferiore non s ma probabilmente uguale (il m...</td>\n",
       "      <td>irrilevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ah però.... uno pensa di averne viste tante su...</td>\n",
       "      <td>Sinceramente una differenza di 9.800? non mi p...</td>\n",
       "      <td>irrilevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Basta darsi delle regole e per questo tipo di ...</td>\n",
       "      <td></td>\n",
       "      <td>irrilevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Personalmente posso ritenermi un possessore di...</td>\n",
       "      <td></td>\n",
       "      <td>positivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Confermo che il posteriore è riuscitissimo e a...</td>\n",
       "      <td>\"sono stato anch'io in conce per altri motivi ...</td>\n",
       "      <td>irrilevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Mi sa che l'unica cosa apprezzabile del rst è ...</td>\n",
       "      <td></td>\n",
       "      <td>irrilevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>grazie ! ! ! ! !</td>\n",
       "      <td></td>\n",
       "      <td>irrilevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Cosimo hai centrato completamente</td>\n",
       "      <td></td>\n",
       "      <td>irrilevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>bisogna distinguere tra le garanzia supplement...</td>\n",
       "      <td></td>\n",
       "      <td>irrilevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Mah parleranno di ipotetiche versioni ibride o...</td>\n",
       "      <td></td>\n",
       "      <td>irrilevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Qual è secondo voi il miglior 4x4 non Suv o fu...</td>\n",
       "      <td></td>\n",
       "      <td>irrilevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>SZ ES-30 ?</td>\n",
       "      <td></td>\n",
       "      <td>irrilevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Ciao perché intitoli il post : \"problemi della...</td>\n",
       "      <td></td>\n",
       "      <td>positivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Diosanto che bello il Rosso 8C confrontato con...</td>\n",
       "      <td></td>\n",
       "      <td>positivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Ax sensazione non vuol dire illusione. Non mi ...</td>\n",
       "      <td></td>\n",
       "      <td>positivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Benvenuta nel posto giusto Allora sentirai div...</td>\n",
       "      <td>\"Buongiorno a tutti So che il titolo di questo...</td>\n",
       "      <td>neutro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Ma come c'è il gpl ! ! ! Ahahaha Nel 2010 se b...</td>\n",
       "      <td></td>\n",
       "      <td>positivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Mitico</td>\n",
       "      <td></td>\n",
       "      <td>irrilevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Infatti la U cromata del paraurti anteriore è ...</td>\n",
       "      <td>modello vecchio tra l'altro... e con pochi sap...</td>\n",
       "      <td>negativo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Si è vero il jimny è un vero fuoristrada. Però...</td>\n",
       "      <td></td>\n",
       "      <td>positivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Hanno limiti di emissioni diversi come in Usa ...</td>\n",
       "      <td></td>\n",
       "      <td>irrilevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Fra l'altro la hybrid con quest'ultimo fl ha b...</td>\n",
       "      <td></td>\n",
       "      <td>positivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Purtroppo accade con tutti i tag... e tra l'al...</td>\n",
       "      <td></td>\n",
       "      <td>irrilevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>RS ? ......quante minchiate che si sentono ! I...</td>\n",
       "      <td></td>\n",
       "      <td>neutro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>voglio aderire pure io ! !</td>\n",
       "      <td></td>\n",
       "      <td>irrilevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>buono a sapersi grazie per le info</td>\n",
       "      <td></td>\n",
       "      <td>irrilevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Occhio che si potrebbe sempre invocare la vers...</td>\n",
       "      <td></td>\n",
       "      <td>neutro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Per ora no rinviato a sabato prossimo</td>\n",
       "      <td>'ragazz scusate l OT e scusate se scrivo ben p...</td>\n",
       "      <td>irrilevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7153</th>\n",
       "      <td>Scusami Tiziano ... non volevo essere scortese...</td>\n",
       "      <td></td>\n",
       "      <td>irrilevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7154</th>\n",
       "      <td>NUOVO LEXUS RX HYBRID 2016 PARTE DA 69.000 EUR...</td>\n",
       "      <td></td>\n",
       "      <td>positivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7155</th>\n",
       "      <td>Dopo tre giorni d'uso posso cominciare ad espr...</td>\n",
       "      <td></td>\n",
       "      <td>irrilevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7156</th>\n",
       "      <td>grazie stanotte sto di servizio in portineria ...</td>\n",
       "      <td></td>\n",
       "      <td>irrilevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7157</th>\n",
       "      <td>Scusate però il fatto che 2 autopareristi abbi...</td>\n",
       "      <td></td>\n",
       "      <td>positivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7158</th>\n",
       "      <td>in altri forum se un utente bannato si re-iscr...</td>\n",
       "      <td></td>\n",
       "      <td>irrilevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7159</th>\n",
       "      <td>E DI QUALSIASI TAGLIA !</td>\n",
       "      <td>Le supposte a qualsiasi ora!</td>\n",
       "      <td>irrilevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7160</th>\n",
       "      <td>Ciao malayes il montaggio delle trombe mi ha a...</td>\n",
       "      <td></td>\n",
       "      <td>irrilevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7161</th>\n",
       "      <td>Ah ecco ero convinto che la coupé 5 cilindri a...</td>\n",
       "      <td></td>\n",
       "      <td>irrilevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7162</th>\n",
       "      <td>Sei sicuro ? si può selezionare anche dal conf...</td>\n",
       "      <td></td>\n",
       "      <td>neutro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7163</th>\n",
       "      <td>Grazie della spiegazione mic1998 !</td>\n",
       "      <td></td>\n",
       "      <td>irrilevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7164</th>\n",
       "      <td>Intendi questa Ypsilon -&amp;gt Lancia Ypsilon - W...</td>\n",
       "      <td></td>\n",
       "      <td>irrilevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7165</th>\n",
       "      <td>Un pelo meno se ci sono solo accessori da cata...</td>\n",
       "      <td></td>\n",
       "      <td>irrilevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7166</th>\n",
       "      <td>Tra le tre nominate vai di Geolandar le AT/S g...</td>\n",
       "      <td></td>\n",
       "      <td>irrilevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7167</th>\n",
       "      <td>Ciao a tutti oggi ho visto una jeep compass L ...</td>\n",
       "      <td></td>\n",
       "      <td>irrilevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7168</th>\n",
       "      <td>ECCO LE FOTO</td>\n",
       "      <td></td>\n",
       "      <td>irrilevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7169</th>\n",
       "      <td>prendila merita di per sè:wink:</td>\n",
       "      <td>\" Però una 3.0csi costa sui 12K davvero bell v...</td>\n",
       "      <td>irrilevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7170</th>\n",
       "      <td>Ciao io ho preso una FIESTA ST LINE 140 cv FUL...</td>\n",
       "      <td></td>\n",
       "      <td>irrilevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7171</th>\n",
       "      <td>bel mezzo parecchio americano come stile</td>\n",
       "      <td></td>\n",
       "      <td>irrilevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7172</th>\n",
       "      <td>Non male tutt'altro. Al posteriore assomiglia ...</td>\n",
       "      <td></td>\n",
       "      <td>irrilevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7173</th>\n",
       "      <td>A me questo aggeggio continua ad ispirare simp...</td>\n",
       "      <td></td>\n",
       "      <td>positivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7174</th>\n",
       "      <td>posto che sono 2 vetture eccezionali e mi par ...</td>\n",
       "      <td></td>\n",
       "      <td>irrilevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7175</th>\n",
       "      <td>Salve a tutti ecco una nuova sezione dedicata ...</td>\n",
       "      <td>'Grande idea......... grazie RossoCorsa'</td>\n",
       "      <td>positivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7176</th>\n",
       "      <td>Inoltre derivavano direttamente dalle corse in...</td>\n",
       "      <td></td>\n",
       "      <td>irrilevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7177</th>\n",
       "      <td>E allora perchè hai scritto sopra \"I modelli N...</td>\n",
       "      <td>'Nemmeno io.'</td>\n",
       "      <td>neutro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7178</th>\n",
       "      <td>Devi vedere 4C come un investimento pubblicita...</td>\n",
       "      <td></td>\n",
       "      <td>positivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7179</th>\n",
       "      <td>Parto con dire una cosa : Bella e molto + bell...</td>\n",
       "      <td>'Caxxo stamattina mi ero preoccupato non veden...</td>\n",
       "      <td>positivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7180</th>\n",
       "      <td>Mi sembri agguerrito ! Bravo ! Ti manderei anc...</td>\n",
       "      <td></td>\n",
       "      <td>irrilevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7181</th>\n",
       "      <td>Grazie per la risposta. In realtà alla fine ho...</td>\n",
       "      <td></td>\n",
       "      <td>irrilevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7182</th>\n",
       "      <td>io l'ho vista dal vivo e ti confremo che è com...</td>\n",
       "      <td></td>\n",
       "      <td>irrilevante</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7183 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  TESTO  \\\n",
       "0     Allora il problema è che non sono aggiornati i...   \n",
       "1     E' virgolettato appositamente.... E soprattutt...   \n",
       "2     Mah io sulla mappa ev-way ho visto solo tipo 2...   \n",
       "3     Ah però.... uno pensa di averne viste tante su...   \n",
       "4     Basta darsi delle regole e per questo tipo di ...   \n",
       "5     Personalmente posso ritenermi un possessore di...   \n",
       "6     Confermo che il posteriore è riuscitissimo e a...   \n",
       "7     Mi sa che l'unica cosa apprezzabile del rst è ...   \n",
       "8                                     grazie ! ! ! ! !    \n",
       "9                    Cosimo hai centrato completamente    \n",
       "10    bisogna distinguere tra le garanzia supplement...   \n",
       "11    Mah parleranno di ipotetiche versioni ibride o...   \n",
       "12    Qual è secondo voi il miglior 4x4 non Suv o fu...   \n",
       "13                                          SZ ES-30 ?    \n",
       "14    Ciao perché intitoli il post : \"problemi della...   \n",
       "15    Diosanto che bello il Rosso 8C confrontato con...   \n",
       "16    Ax sensazione non vuol dire illusione. Non mi ...   \n",
       "17    Benvenuta nel posto giusto Allora sentirai div...   \n",
       "18    Ma come c'è il gpl ! ! ! Ahahaha Nel 2010 se b...   \n",
       "19                                               Mitico   \n",
       "20    Infatti la U cromata del paraurti anteriore è ...   \n",
       "21    Si è vero il jimny è un vero fuoristrada. Però...   \n",
       "22    Hanno limiti di emissioni diversi come in Usa ...   \n",
       "23    Fra l'altro la hybrid con quest'ultimo fl ha b...   \n",
       "24    Purtroppo accade con tutti i tag... e tra l'al...   \n",
       "25    RS ? ......quante minchiate che si sentono ! I...   \n",
       "26                          voglio aderire pure io ! !    \n",
       "27                  buono a sapersi grazie per le info    \n",
       "28    Occhio che si potrebbe sempre invocare la vers...   \n",
       "29               Per ora no rinviato a sabato prossimo    \n",
       "...                                                 ...   \n",
       "7153  Scusami Tiziano ... non volevo essere scortese...   \n",
       "7154  NUOVO LEXUS RX HYBRID 2016 PARTE DA 69.000 EUR...   \n",
       "7155  Dopo tre giorni d'uso posso cominciare ad espr...   \n",
       "7156  grazie stanotte sto di servizio in portineria ...   \n",
       "7157  Scusate però il fatto che 2 autopareristi abbi...   \n",
       "7158  in altri forum se un utente bannato si re-iscr...   \n",
       "7159                           E DI QUALSIASI TAGLIA !    \n",
       "7160  Ciao malayes il montaggio delle trombe mi ha a...   \n",
       "7161  Ah ecco ero convinto che la coupé 5 cilindri a...   \n",
       "7162  Sei sicuro ? si può selezionare anche dal conf...   \n",
       "7163                Grazie della spiegazione mic1998 !    \n",
       "7164  Intendi questa Ypsilon -&gt Lancia Ypsilon - W...   \n",
       "7165  Un pelo meno se ci sono solo accessori da cata...   \n",
       "7166  Tra le tre nominate vai di Geolandar le AT/S g...   \n",
       "7167  Ciao a tutti oggi ho visto una jeep compass L ...   \n",
       "7168                                      ECCO LE FOTO    \n",
       "7169                   prendila merita di per sè:wink:    \n",
       "7170  Ciao io ho preso una FIESTA ST LINE 140 cv FUL...   \n",
       "7171          bel mezzo parecchio americano come stile    \n",
       "7172  Non male tutt'altro. Al posteriore assomiglia ...   \n",
       "7173  A me questo aggeggio continua ad ispirare simp...   \n",
       "7174  posto che sono 2 vetture eccezionali e mi par ...   \n",
       "7175  Salve a tutti ecco una nuova sezione dedicata ...   \n",
       "7176  Inoltre derivavano direttamente dalle corse in...   \n",
       "7177  E allora perchè hai scritto sopra \"I modelli N...   \n",
       "7178  Devi vedere 4C come un investimento pubblicita...   \n",
       "7179  Parto con dire una cosa : Bella e molto + bell...   \n",
       "7180  Mi sembri agguerrito ! Bravo ! Ti manderei anc...   \n",
       "7181  Grazie per la risposta. In realtà alla fine ho...   \n",
       "7182  io l'ho vista dal vivo e ti confremo che è com...   \n",
       "\n",
       "                                         (Testo Citato)        Brand  \n",
       "0                                                        irrilevante  \n",
       "1                                                        irrilevante  \n",
       "2     'Inferiore non s ma probabilmente uguale (il m...  irrilevante  \n",
       "3     Sinceramente una differenza di 9.800? non mi p...  irrilevante  \n",
       "4                                                        irrilevante  \n",
       "5                                                           positivo  \n",
       "6     \"sono stato anch'io in conce per altri motivi ...  irrilevante  \n",
       "7                                                        irrilevante  \n",
       "8                                                        irrilevante  \n",
       "9                                                        irrilevante  \n",
       "10                                                       irrilevante  \n",
       "11                                                       irrilevante  \n",
       "12                                                       irrilevante  \n",
       "13                                                       irrilevante  \n",
       "14                                                          positivo  \n",
       "15                                                          positivo  \n",
       "16                                                          positivo  \n",
       "17    \"Buongiorno a tutti So che il titolo di questo...       neutro  \n",
       "18                                                          positivo  \n",
       "19                                                       irrilevante  \n",
       "20    modello vecchio tra l'altro... e con pochi sap...     negativo  \n",
       "21                                                          positivo  \n",
       "22                                                       irrilevante  \n",
       "23                                                          positivo  \n",
       "24                                                       irrilevante  \n",
       "25                                                            neutro  \n",
       "26                                                       irrilevante  \n",
       "27                                                       irrilevante  \n",
       "28                                                            neutro  \n",
       "29    'ragazz scusate l OT e scusate se scrivo ben p...  irrilevante  \n",
       "...                                                 ...          ...  \n",
       "7153                                                     irrilevante  \n",
       "7154                                                        positivo  \n",
       "7155                                                     irrilevante  \n",
       "7156                                                     irrilevante  \n",
       "7157                                                        positivo  \n",
       "7158                                                     irrilevante  \n",
       "7159                       Le supposte a qualsiasi ora!  irrilevante  \n",
       "7160                                                     irrilevante  \n",
       "7161                                                     irrilevante  \n",
       "7162                                                          neutro  \n",
       "7163                                                     irrilevante  \n",
       "7164                                                     irrilevante  \n",
       "7165                                                     irrilevante  \n",
       "7166                                                     irrilevante  \n",
       "7167                                                     irrilevante  \n",
       "7168                                                     irrilevante  \n",
       "7169  \" Però una 3.0csi costa sui 12K davvero bell v...  irrilevante  \n",
       "7170                                                     irrilevante  \n",
       "7171                                                     irrilevante  \n",
       "7172                                                     irrilevante  \n",
       "7173                                                        positivo  \n",
       "7174                                                     irrilevante  \n",
       "7175           'Grande idea......... grazie RossoCorsa'     positivo  \n",
       "7176                                                     irrilevante  \n",
       "7177                                      'Nemmeno io.'       neutro  \n",
       "7178                                                        positivo  \n",
       "7179  'Caxxo stamattina mi ero preoccupato non veden...     positivo  \n",
       "7180                                                     irrilevante  \n",
       "7181                                                     irrilevante  \n",
       "7182                                                     irrilevante  \n",
       "\n",
       "[7183 rows x 3 columns]"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('dataset.csv').fillna('')[['TESTO', '(Testo Citato)', 'Brand']]\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp = Preprocessor()\n",
    "# TESTO\n",
    "for i in range(len(dataset)):\n",
    "    dataset['TESTO'][i] = pp.preprocessText(dataset['TESTO'][i], method='word', use_stemmer=True, ner=True)\n",
    "# (Testo Citato)\n",
    "for i in range(len(dataset)):\n",
    "    dataset['(Testo Citato)'][i] = pp.preprocessText(dataset['(Testo Citato)'][i], method='word', use_stemmer=True, ner=True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine labels \"molto positivo\" = \"positivo\" and so on\n",
    "dataset['Brand'] = dataset['Brand'].replace('molto positivo', 'positivo')\n",
    "dataset['Brand'] = dataset['Brand'].replace('molto negativo', 'negativo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_dataset = []\n",
    "for i in range(len(dataset)):\n",
    "    preprocessed_dataset.append((combine_text_quote(dataset['TESTO'][i], dataset['(Testo Citato)'][i]), dataset['Brand'][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('bisogn_TEXT distingu_TEXT tra_TEXT le_TEXT garanz_TEXT supplementar_TEXT cio_TEXT quell_TEXT acquist_TEXT success_TEXT in_TEXT cui_TEXT firm_TEXT un_TEXT ver_TEXT e_TEXT pror_TEXT contratt_TEXT un_TEXT cui_TEXT esul_TEXT l_TEXT applic_TEXT del_TEXT decret_TEXT mont_TEXT e_TEXT la_TEXT garanz_TEXT tip_TEXT quell_TEXT corean_TEXT che_TEXT son_TEXT dirett_TEXT di_TEXT 5/7_TEXT anni_TEXT EMARK_TEXT _TEXT _QUOTE',\n",
       " 'irrilevante')"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_dataset[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split into training and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length: 7183\n"
     ]
    }
   ],
   "source": [
    "numpy_dataset = np.array(preprocessed_dataset)\n",
    "print('Length: ' + str(numpy_dataset.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(numpy_dataset)\n",
    "train_dataset, test_dataset = numpy_dataset[:6000,:], numpy_dataset[6000:,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'irrilevante': 4849, 'neutro': 238, 'positivo': 538, 'negativo': 375})"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collections.Counter(train_dataset[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit vectorizer\n",
    "MAX_FEATURES = 10000\n",
    "vec = Vectorizer(X_dataset, method='bow', max_features=MAX_FEATURES, ngrams=2, just_presence=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try\n",
    "vec.vectorize('bisogn_TEXT distingu_TEXT tra_TEXT le_TEXT').toarray()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally replace text with vector, and replace label with numerical representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final dataset for the classification\n",
    "train_X = np.empty([train_dataset.shape[0], MAX_FEATURES])\n",
    "train_y = np.empty([train_dataset.shape[0], 1])\n",
    "\n",
    "for i in range(train_dataset.shape[0]):\n",
    "    #train_X[i] = vec.vectorize(train_dataset[i, 0]).toarray()[0].copy()\n",
    "    # copy vectorized elements in final dataset\n",
    "    vectorized = vec.vectorize(train_dataset[i, 0]).toarray()[0]\n",
    "    for j in range(train_X.shape[1]):\n",
    "        train_X[i,j] = vectorized[j]\n",
    "    if train_dataset[i, 1] == 'irrilevante':\n",
    "        train_y[i] = 0\n",
    "    elif train_dataset[i, 1] == 'positivo':\n",
    "        train_y[i] = 1\n",
    "    elif train_dataset[i, 1] == 'neutro':\n",
    "        train_y[i] = 2\n",
    "    elif train_dataset[i, 1] == 'negativo':\n",
    "        train_y[i] = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM _TFIDF Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/automated-machine-learning-hyperparameter-tuning-in-python-dfda59b72f8a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................................... , score=0.742, total= 4.3min\n",
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  4.3min remaining:    0.0s\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................................... , score=0.751, total= 4.3min\n",
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  8.5min remaining:    0.0s\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "clf = svm.SVC(kernel='linear', C=1)\n",
    "scores = cross_val_score(clf, train_X, train_y, cv=4, verbose=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
